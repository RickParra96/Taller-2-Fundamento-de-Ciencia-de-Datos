{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PredicciÃ³n de Churn en **Beta Bank**\n",
        "\n",
        "---\n",
        "\n",
        "## 1) **Business Understanding**\n",
        "\n",
        "### 1.1. Contexto\n",
        "Los clientes de **Beta Bank** estÃ¡n abandonando el banco gradualmente. Captar clientes nuevos es mÃ¡s costoso que retener a los actuales. Necesitamos **identificar a tiempo** a quienes tienen alta probabilidad de churn para priorizar acciones de retenciÃ³n.\n",
        "\n",
        "### 1.2. Problema de negocio\n",
        "Crear un sistema de **clasificaciÃ³n binaria** que prediga si un cliente **se irÃ¡** pronto.\n",
        "\n",
        "- **Variable objetivo**: `Exited` (1 = se fue, 0 = se queda)\n",
        "\n",
        "### 1.3. MÃ©tricas y criterios de Ã©xito\n",
        "- **MÃ©trica principal**: F1 en el **conjunto de prueba** $\\rightarrow$ **F1 â‰¥ 0.70**.  \n",
        "- **MÃ©trica secundaria**: AUC-ROC (comparar y discutir con F1).  \n",
        "- JustificaciÃ³n:\n",
        "  - **F1** equilibra *precision* y *recall* ante **desequilibrio** de clases.  \n",
        "  - **AUC-ROC** evalÃºa la capacidad de ranking del modelo.\n",
        "\n",
        "**Recordatorio de fÃ³rmulas**:  \n",
        "- F1 (macro-definiciÃ³n binaria):\n",
        "  $$\n",
        "  F1 = \\frac{2 \\cdot \\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "  $$\n",
        "- Donde:\n",
        "  - $\\text{Precision} = \\frac{TP}{TP+FP}$  \n",
        "  - $\\text{Recall} = \\frac{TP}{TP+FN}$\n",
        "\n",
        "---\n",
        "\n",
        "## 2) **Data Understanding**\n",
        "\n",
        "### 2.1. Fuente y acceso\n",
        "- **Ruta**: `/datasets/Churn.csv`\n",
        "\n",
        "### 2.2. Diccionario de datos (resumen)\n",
        "**CaracterÃ­sticas**\n",
        "- `RowNumber`: Ã­ndice de fila  \n",
        "- `CustomerId`: identificador Ãºnico  \n",
        "- `Surname`: apellido  \n",
        "- `CreditScore`: score de crÃ©dito  \n",
        "- `Geography`: paÃ­s de residencia  \n",
        "- `Gender`: sexo  \n",
        "- `Age`: edad  \n",
        "- `Tenure`: antigÃ¼edad del depÃ³sito (aÃ±os)  \n",
        "- `Balance`: saldo  \n",
        "- `NumOfProducts`: nÃºmero de productos bancarios  \n",
        "- `HasCrCard`: tiene tarjeta (1/0)  \n",
        "- `IsActiveMember`: cliente activo (1/0)  \n",
        "- `EstimatedSalary`: salario estimado\n",
        "\n",
        "**Objetivo**\n",
        "- `Exited`: churn (1/0)\n",
        "\n",
        "### 2.3. Tareas de comprensiÃ³n de datos (sin cÃ³digo)\n",
        "- [ ] Verifica cantidad de filas y columnas, **tipos de datos**, valores faltantes, duplicados.  \n",
        "- [ ] Revisa **estadÃ­sticos descriptivos** de variables numÃ©ricas y cardinalidad de categÃ³ricas.  \n",
        "- [ ] Analiza **distribuciones** y posibles **outliers** (Balance, Age, EstimatedSalary).  \n",
        "- [ ] EvalÃºa **correlaciones** y relaciones relevantes con `Exited`.  \n",
        "- [ ] **Equilibrio de clases**: calcula la proporciÃ³n de `Exited=1` vs `Exited=0`.\n",
        "\n",
        "> **Requisito** (instrucciÃ³n del proyecto):  \n",
        "> Entrena **un primer modelo base sin tratar el desequilibrio** y registra hallazgos (quÃ© tan mal/bien va F1 y AUC-ROC).\n",
        "\n",
        "---\n",
        "\n",
        "## 3) **Data Preparation**\n",
        "\n",
        "> Objetivo: transformar datos crudos en un conjunto listo para modelado, **sin fuga de informaciÃ³n**.\n",
        "\n",
        "### 3.1. Limpieza y validaciones\n",
        "- [ ] Tratamiento de **valores faltantes** (numerical / categorical).  \n",
        "- [ ] DetecciÃ³n y manejo de **duplicados**.  \n",
        "- [ ] Chequeo de **rangos vÃ¡lidos** (edad positiva, saldos no negativos, etc.).  \n",
        "- [ ] Decisiones documentadas: imputaciÃ³n, exclusiÃ³n o transformaciÃ³n.\n",
        "\n",
        "### 3.2. IngenierÃ­a de caracterÃ­sticas (opcional, sugerida)\n",
        "- [ ] Variables derivadas:\n",
        "  - *Ratios* (p.ej., `Balance/EstimatedSalary`),  \n",
        "  - *Binning* de `Age` o `Tenure`,  \n",
        "  - Interacciones si aportan.  \n",
        "- [ ] NormalizaciÃ³n/EstandarizaciÃ³n para modelos sensibles a escala.\n",
        "\n",
        "### 3.3. CodificaciÃ³n de variables categÃ³ricas\n",
        "- [ ] **`Geography`, `Gender`**: *One-Hot Encoding* o *Target Encoding* (justifica elecciÃ³n).  \n",
        "- Evita **leakage**: ajusta codificadores **solo con entrenamiento**.\n",
        "\n",
        "### 3.4. DivisiÃ³n de datos\n",
        "- [ ] **Stratified** *train/validation/test* (p. ej., 60/20/20 o 70/15/15).  \n",
        "- MantÃ©n la **misma proporciÃ³n de clases** en cada conjunto.  \n",
        "- Fija `random_state` y documenta el **protocolo de evaluaciÃ³n**.\n",
        "\n",
        "> **Nota**: Todo el preprocesamiento debe ir dentro de **pipelines** (conceptualmente) para evitar fugas entre train/valid/test.\n",
        "\n",
        "---\n",
        "\n",
        "## 4) **Modeling**\n",
        "\n",
        "### 4.1. LÃ­nea base (baseline)\n",
        "- [ ] Entrena un modelo sencillo **sin tratar desequilibrio** (p. ej., RegresiÃ³n LogÃ­stica / Ãrbol simple).  \n",
        "- [ ] Registra F1 y AUC-ROC en **validaciÃ³n**.  \n",
        "- [ ] Usa esta lÃ­nea base como referencia.\n",
        "\n",
        "### 4.2. Enfoques para el **desequilibrio de clases** (usa **al menos dos**)\n",
        "- **PonderaciÃ³n**: `class_weight='balanced'` en modelos compatibles.  \n",
        "- **Re-muestreo**:\n",
        "  - **Oversampling** (p. ej., **SMOTE** / Random OverSampling).  \n",
        "  - **Undersampling** (Random UnderSampling).  \n",
        "- **Ajuste de umbral** (*threshold moving*):\n",
        "  - Selecciona el umbral de probabilidad que **maximiza F1** en validaciÃ³n.  \n",
        "- (Opcional) **Enfoques en el espacio de decisiones**: ensembles focalizados, calibraciÃ³n de probabilidades.\n",
        "\n",
        "> Sugerencia: compara **al menos 2** tÃ©cnicas (p. ej., *class_weight* vs **SMOTE**).\n",
        "\n",
        "### 4.3. Modelos a evaluar (requeridos)\n",
        "Entrena y compara (en *validation*) varios algoritmos:\n",
        "- **Logistic Regression**\n",
        "- **Tree** (e.g., `DecisionTreeClassifier`)  \n",
        "- **Random Forest** (`RandomForestClassifier`)  \n",
        "\n",
        "> Documenta: hiperparÃ¡metros, tÃ©cnica de re-muestreo/ponderaciÃ³n usada y resultados.\n",
        "\n",
        "### 4.4. BÃºsqueda de hiperparÃ¡metros\n",
        "- [ ] Usa validaciÃ³n cruzada estratificada en **conjunto de entrenamiento** y evalÃºa en **validaciÃ³n**.  \n",
        "- [ ] Prueba **GridSearch** (o RandomizedSearch si es mÃ¡s eficiente).  \n",
        "- [ ] Escoge la **mejor combinaciÃ³n** por **F1** (criterio primario).  \n",
        "- [ ] **Ajusta umbral** del mejor modelo segÃºn la curva **Precision-Recall** para maximizar F1.\n",
        "\n",
        "### 4.5. MÃ©tricas y artefactos a registrar (en validaciÃ³n)\n",
        "- [ ] **F1** y **AUC-ROC**.  \n",
        "- [ ] Matriz de confusiÃ³n (TP, FP, TN, FN).  \n",
        "- [ ] Curvas ROC y Precision-Recall.  \n",
        "- [ ] Importancia de variables.\n",
        "- [ ] Umbral Ã³ptimo elegido y motivaciÃ³n.\n",
        "\n",
        "---\n",
        "\n",
        "## 5) **Evaluation**\n",
        "\n",
        "### 5.1. Prueba final (Test)\n",
        "- [ ] Reentrena (si corresponde) con **train+valid** y evalÃºa en **test**.  \n",
        "- [ ] Reporta **F1 (debe ser â‰¥ 0.70)** y **AUC-ROC** en **test**.  \n",
        "- [ ] Compara y discute F1 vs AUC-ROC:\n",
        "  - Â¿El modelo ranquea bien (AUC-ROC alto) pero falla en el umbral para F1?  \n",
        "  - Â¿El ajuste de umbral mejorÃ³ F1 sin degradar demasiado AUC-ROC?\n",
        "\n",
        "### 5.2. AnÃ¡lisis de error y robustez\n",
        "- [ ] Segmenta desempeÃ±o por **Geography**, **Gender**, **Age groups**, **IsActiveMember**.  \n",
        "- [ ] Identifica **sesgos** o grupos con alto **FN** (falsos negativos) y propone mitigaciones.  \n",
        "- [ ] Chequea estabilidad del modelo (variaciÃ³n por semillas / folds).\n",
        "\n",
        "### 5.3. Conclusiones\n",
        "- [ ] Resume: **mejor modelo**, tÃ©cnica(s) anti-desequilibrio, umbral final, y mÃ©tricas clave en **test**.  \n",
        "- [ ] Discute **riesgos** (leakage, sobreajuste, dependencia de re-muestreo).\n",
        "\n",
        "---\n",
        "\n",
        "## 6) **Deployment**\n",
        "\n",
        "Exportar el modelo como binario\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Ž Anexos\n",
        "\n",
        "### A) DescripciÃ³n completa de los datos\n",
        "- `RowNumber` (int) â€” Ã­ndice de fila  \n",
        "- `CustomerId` (int/str) â€” id Ãºnico  \n",
        "- `Surname` (str) â€” apellido  \n",
        "- `CreditScore` (num) â€” score de crÃ©dito  \n",
        "- `Geography` (cat) â€” paÃ­s  \n",
        "- `Gender` (cat) â€” sexo  \n",
        "- `Age` (num) â€” edad  \n",
        "- `Tenure` (num) â€” aÃ±os de antigÃ¼edad del depÃ³sito  \n",
        "- `Balance` (num) â€” saldo  \n",
        "- `NumOfProducts` (num) â€” nÂº de productos  \n",
        "- `HasCrCard` (bin) â€” tarjeta (1/0)  \n",
        "- `IsActiveMember` (bin) â€” activo (1/0)  \n",
        "- `EstimatedSalary` (num) â€” salario estimado  \n",
        "- **Objetivo**: `Exited` (bin)\n",
        "\n",
        "### B) Posibles fugas de informaciÃ³n (evÃ­talas)\n",
        "- Usar **estadÃ­sticos globales** calculados con todo el dataset para imputaciÃ³n/encoding antes del split.  \n",
        "- Aplicar **SMOTE/undersampling/oversampling/standardization** fuera del **pipeline** (deben ajustarse usando **solo** train).  \n",
        "- SelecciÃ³n de variables basada en toda la data (hazla con *cross-validation* o dentro de pipeline).\n",
        "\n",
        "### C) Estructura sugerida del *repo/cuaderno*\n",
        "- **Secciones** de este documento como tÃ­tulos de celdas Markdown.  \n",
        "- **Resultados** y **grÃ¡ficos** colocados al final de cada etapa con una mini-conclusiÃ³n.\n",
        "\n",
        "---\n",
        "\n",
        "## Rubrica de EvaluaciÃ³n (Checklist para revisiÃ³n)\n",
        "\n",
        "- [ ] PreparaciÃ³n de datos clara y correcta (todos los tipos procesados).  \n",
        "- [ ] ExplicaciÃ³n de pasos de preprocesamiento y decisiones justificadas.  \n",
        "- [ ] InvestigaciÃ³n del **equilibrio de clases** y baseline sin correcciÃ³n.  \n",
        "- [ ] Al menos **dos tÃ©cnicas** para corregir desequilibrio (**class_weight**, **SMOTE/over**, **under**, **over**,**threshold**).  \n",
        "- [ ] DivisiÃ³n **estratificada** y protocolo de validaciÃ³n bien definido.  \n",
        "- [ ] Entrenamiento, validaciÃ³n y prueba **correctos y reproducibles**.  \n",
        "- [ ] **F1 en test â‰¥ 0.70** reportado junto a **AUC-ROC**.  \n",
        "- [ ] ComparaciÃ³n y anÃ¡lisis crÃ­tico **F1 vs AUC-ROC**.  \n",
        "- [ ] Estructura clara, limpieza y orden del cuaderno.\n"
      ],
      "metadata": {
        "id": "agoLtLNEAJXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROCâ€“AUC (enfoque prÃ¡ctico)\n",
        "\n",
        "## QuÃ© mide\n",
        "- **ROC**: curva de pares $(\\mathrm{FPR}(\\tau), \\mathrm{TPR}(\\tau))$ al variar el umbral $\\tau$.\n",
        "  - $\\mathrm{TPR}=\\frac{TP}{TP+FN}$ (recall),  \n",
        "    $\\mathrm{FPR}=\\frac{FP}{FP+TN}$.\n",
        "- **AUC**: Ã¡rea bajo la ROC. InterpretaciÃ³n clave:\n",
        "  $$\n",
        "  \\mathrm{AUC}=\\mathbb{P}(S_1>S_0)+\\tfrac{1}{2}\\mathbb{P}(S_1=S_0)\n",
        "  $$\n",
        "  Probabilidad de que un positivo tenga **mayor score** que un negativo (mide **ranking**, no calibraciÃ³n).\n",
        "\n",
        "## Por quÃ© importa\n",
        "- Invariante a transformaciones monÃ³tonas del score y **poco sensible a la prevalencia** de la clase.\n",
        "- Resume el rendimiento para **todos los umbrales**; Ãºtil para comparar modelos sin fijar $\\tau$.\n",
        "\n",
        "## CuÃ¡ndo usar (y cuÃ¡ndo no)\n",
        "- Para **elegir modelo** por capacidad de ranking global.\n",
        "- En **datasets muy desbalanceados**, AUC puede verse optimista. Complementa con **PR/AUC-PR** y **F1**.\n",
        "\n",
        "## SelecciÃ³n de umbral (lo operativo)\n",
        "- AUC no da el umbral. Elige $\\tau$ segÃºn objetivo:\n",
        "  - **Max F1** si balanceas precisiÃ³n y recall.\n",
        "  - **Costo mÃ­nimo** si tienes matriz de costos:\n",
        "    $$\n",
        "    \\mathbb{E}[C]=C_{FP}\\cdot FP(\\tau)+C_{FN}\\cdot FN(\\tau)\n",
        "    $$\n",
        "- Usa curvas **Precisionâ€“Recall** y la **matriz de confusiÃ³n** para justificar la decisiÃ³n.\n",
        "\n",
        "## Buenas prÃ¡cticas\n",
        "1. Separar **train/valid/test** y evitar **leakage** en todo el preprocesamiento.\n",
        "2. Comparar modelos con **AUC (Â± IC)** y reportar tambiÃ©n **F1**, **precision**, **recall**.\n",
        "3. Analizar **PR/AUC-PR** si hay fuerte desequilibrio.\n",
        "4. Reportar el **umbral final** y por quÃ© lo elegiste.\n",
        "5. Considerar **calibraciÃ³n** (e.g., Platt/IsotÃ³nica) si usarÃ¡s **probabilidades** en negocio.\n",
        "\n",
        "## Miniâ€“resumen para decidir rÃ¡pido\n",
        "- **Escoger modelo**: mira **AUC** (y AUC-PR si desbalanceado).\n",
        "- **Operar**: fija **umbral** para tu objetivo (F1 o costo).\n",
        "- **Monitorear**: revisa F1/ROCâ€“AUC periÃ³dicamente y reentrena ante *drift*.\n",
        "\n",
        "**Reglas de pulgar**  \n",
        "- AUC â‰ˆ 0.5: aleatorio; 0.7â€“0.8: aceptable; 0.8â€“0.9: bueno; >0.9: excelente (verifica que no haya fuga).\n"
      ],
      "metadata": {
        "id": "wcWLKX8QB75t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SLgSonq0B8Ik"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}